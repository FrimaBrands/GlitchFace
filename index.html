<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Face Blur Camera (with fallback)</title>
  <style>
    :root { --bg:#0b0d10; --fg:#e7eaee; --muted:#98a2b3; --card:#12161b; --accent:#6ea8fe; }
    * { box-sizing: border-box; }
    html, body { height: 100%; margin: 0; background: var(--bg); color: var(--fg); font: 14px/1.4 system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; }
    .wrap { min-height: 100%; display: grid; place-items: center; padding: 24px; }
    .card { width: min(960px, 92vw); background: var(--card); border: 1px solid #1d232c; border-radius: 20px; box-shadow: 0 10px 30px rgba(0,0,0,.35); overflow: hidden; }
    .stage { position: relative; background: #000; aspect-ratio: 16/9; }
    video, canvas { position: absolute; inset: 0; width: 100%; height: 100%; }
    video { opacity: 0; pointer-events: none; } /* draw to canvas */
    .ui { display: flex; flex-wrap: wrap; gap: 10px 14px; padding: 14px 16px; align-items: center; border-top: 1px solid #1d232c; }
    .ui .spacer { flex: 1 1 auto; }
    .btn { appearance: none; border: 1px solid #223; background: #10151b; color: var(--fg); padding: 10px 14px; border-radius: 12px; cursor: pointer; font-weight: 600; }
    .btn[disabled] { opacity: .5; cursor: not-allowed; }
    .btn.primary { background: var(--accent); border-color: var(--accent); color: #0a0b0e; }
    label { display: inline-flex; gap: 8px; align-items: center; color: var(--muted); }
    input[type="range"] { width: 180px; }
    .status { color: var(--muted); }
    details { padding: 0 16px 14px; color: var(--muted); }
    kbd { background:#0c1016; padding:2px 6px; border-radius:6px; border:1px solid #1d232c; }
  </style>
  <!-- MediaPipe fallback (loads only if needed) -->
  <script defer src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection@0.4/face_detection.js"></script>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <div class="stage">
        <video id="video" playsinline muted></video>
        <canvas id="canvas"></canvas>
      </div>

      <div class="ui">
        <button id="startBtn" class="btn primary">Start camera</button>
        <button id="stopBtn" class="btn" disabled>Stop</button>
        <span class="spacer"></span>
        <label>Blur
          <input id="blurStrength" type="range" min="6" max="40" value="22" />
        </label>
        <label><input id="mirror" type="checkbox" checked /> Mirror</label>
        <label><input id="showBoxes" type="checkbox" /> Show boxes</label>
        <span class="spacer"></span>
        <span id="status" class="status">Idle</span>
      </div>

      <details>
        <summary>Troubleshooting</summary>
        <ul>
          <li>Run from a server (VS Code <b>Live Server</b> is fine) — <code>file://</code> won’t work.</li>
          <li><b>Fallback:</b> automatically uses MediaPipe Face Detection if <code>FaceDetector</code> is missing.</li>
          <li>If the preview is black, ensure camera permission is granted and no other app is using the webcam.</li>
        </ul>
        <div>Shortcuts: <kbd>Space</kbd> start/stop, <kbd>M</kbd> mirror, <kbd>B</kbd> boxes.</div>
      </details>
    </div>
  </div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const startBtn = document.getElementById('startBtn');
    const stopBtn  = document.getElementById('stopBtn');
    const blurStrength = document.getElementById('blurStrength');
    const mirror = document.getElementById('mirror');
    const showBoxes = document.getElementById('showBoxes');
    const statusEl = document.getElementById('status');

    let stream = null;
    let rafId = null;
    let lastDetections = [];      // {x,y,width,height} in pixels
    let detTimer = 0;
    const detectIntervalMs = 90;  // ~11 fps
    const pad = 28;               // extra blur around face
    let provider = 'none';        // 'shape' or 'mediapipe'
    let shapeDetector = null;     // FaceDetector
    let mpDetector = null;        // MediaPipe FaceDetection
    let mpInFlight = false;

    const blurCanvas = document.createElement('canvas');
    const blurCtx = blurCanvas.getContext('2d');

    function setStatus(msg) { statusEl.textContent = msg; }

    function fitCanvasToVideo() {
      const w = video.videoWidth || 1280;
      const h = video.videoHeight || 720;
      canvas.width = w; canvas.height = h;
      blurCanvas.width = w; blurCanvas.height = h;
    }

    function mirrorX(x, width, totalWidth) {
      return totalWidth - (x + width);
    }

    function roundRectPath(c, x, y, w, h, r=22) {
      if (c.roundRect) { c.beginPath(); c.roundRect(x, y, w, h, r); return; }
      const rr = Math.min(r, w/2, h/2);
      c.beginPath();
      c.moveTo(x+rr, y);
      c.arcTo(x+w, y, x+w, y+h, rr);
      c.arcTo(x+w, y+h, x, y+h, rr);
      c.arcTo(x, y+h, x, y, rr);
      c.arcTo(x, y, x+w, y, rr);
      c.closePath();
    }

    async function initDetector() {
      if ('FaceDetector' in window) {
        shapeDetector = new FaceDetector({ fastMode: true, maxDetectedFaces: 5 });
        provider = 'shape';
        setStatus('Camera running. Detecting (Shape Detection)…');
        return;
      }
      // MediaPipe fallback
      if (window.FaceDetection && window.FaceDetection.FaceDetection) {
        mpDetector = new window.FaceDetection.FaceDetection({
          locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection@0.4/${file}`
        });
        mpDetector.setOptions({
          model: 'short',               // fast, near-range
          minDetectionConfidence: 0.6
        });
        mpDetector.onResults((res) => {
          const w = canvas.width, h = canvas.height;
          lastDetections = (res.detections || []).map(d => {
            const bb = d.locationData.relativeBoundingBox;
            return {
              x: Math.max(0, bb.xMin * w),
              y: Math.max(0, bb.yMin * h),
              width: Math.min(w, bb.width * w),
              height: Math.min(h, bb.height * h)
            };
          });
        });
        provider = 'mediapipe';
        setStatus('Camera running. Detecting (MediaPipe)…');
        return;
      }
      throw new Error('No face detection available (Shape Detection & MediaPipe missing).');
    }

    async function start() {
      try {
        setStatus('Requesting camera…');
        startBtn.disabled = true;
        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
        video.srcObject = stream;

        await new Promise(res => video.onloadedmetadata = res);
        await video.play();

        fitCanvasToVideo();
        window.addEventListener('resize', fitCanvasToVideo);

        await initDetector(); // picks shape or mediapipe
        stopBtn.disabled = false;

        loop(performance.now());
      } catch (err) {
        console.error(err);
        setStatus('Error: ' + err.message);
        startBtn.disabled = false;
        stopBtn.disabled = true;
      }
    }

    function stop() {
      cancelAnimationFrame(rafId);
      rafId = null;
      if (stream) { stream.getTracks().forEach(t => t.stop()); stream = null; }
      shapeDetector = null; mpDetector = null; provider = 'none';
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      stopBtn.disabled = true; startBtn.disabled = false;
      setStatus('Stopped');
    }

    async function loop(now) {
      if (!stream) return;

      const w = canvas.width, h = canvas.height;

      // Draw current frame
      ctx.save();
      if (mirror.checked) { ctx.translate(w, 0); ctx.scale(-1, 1); }
      ctx.drawImage(video, 0, 0, w, h);
      ctx.restore();

      // Prepare blurred copy of the frame
      blurCtx.filter = `blur(${+blurStrength.value}px)`;
      blurCtx.drawImage(canvas, 0, 0, w, h);

      // Throttled detection
      if (!detTimer || (now - detTimer) > detectIntervalMs) {
        detTimer = now;
        if (provider === 'shape' && shapeDetector) {
          try {
            const ds = await shapeDetector.detect(video);
            // Normalize to pixel boxes
            lastDetections = (ds || []).map(d => d.boundingBox);
          } catch (e) { /* ignore transient errors */ }
        } else if (provider === 'mediapipe' && mpDetector && !mpInFlight) {
          mpInFlight = true;
          mpDetector.send({ image: video }).finally(() => { mpInFlight = false; });
        }
      }

      // Draw blur over faces
      for (const box of lastDetections) {
        let x = box.x, y = box.y, wBox = box.width, hBox = box.height;
        if (mirror.checked) x = mirrorX(x, wBox, w);
        x = Math.max(0, Math.floor(x - pad));
        y = Math.max(0, Math.floor(y - pad));
        wBox = Math.min(w - x, Math.ceil(wBox + pad * 2));
        hBox = Math.min(h - y, Math.ceil(hBox + pad * 2));

        ctx.save();
        roundRectPath(ctx, x, y, wBox, hBox, 22);
        ctx.clip();
        ctx.drawImage(blurCanvas, 0, 0);
        ctx.restore();

        if (showBoxes.checked) {
          ctx.save();
          ctx.lineWidth = 2;
          ctx.strokeStyle = 'rgba(110,168,254,.9)';
          roundRectPath(ctx, x, y, wBox, hBox, 22);
          ctx.stroke();
          ctx.restore();
        }
      }

      rafId = requestAnimationFrame(loop);
    }

    startBtn.addEventListener('click', start);
    stopBtn.addEventListener('click', stop);

    window.addEventListener('keydown', (e) => {
      if (e.code === 'Space') { e.preventDefault(); (stream ? stop : start)(); }
      else if (e.key.toLowerCase() === 'm') { mirror.checked = !mirror.checked; }
      else if (e.key.toLowerCase() === 'b') { showBoxes.checked = !showBoxes.checked; }
    });
  </script>
</body>
</html>
