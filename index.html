<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Face Blur (MediaPipe, GitHub Pages)</title>
  <style>
    :root { --bg:#0b0d10; --fg:#e7eaee; --muted:#98a2b3; --card:#12161b; --accent:#6ea8fe; }
    * { box-sizing: border-box; }
    html,body{height:100%;margin:0;background:var(--bg);color:var(--fg);font:14px/1.4 system-ui,Segoe UI,Roboto,Helvetica,Arial,sans-serif}
    .wrap{min-height:100%;display:grid;place-items:center;padding:24px}
    .card{width:min(960px,92vw);background:var(--card);border:1px solid #1d232c;border-radius:20px;box-shadow:0 10px 30px rgba(0,0,0,.35);overflow:hidden}
    .stage{position:relative;background:#000;aspect-ratio:16/9}
    video,canvas{position:absolute;inset:0;width:100%;height:100%}
    video{opacity:0;pointer-events:none}
    .ui{display:flex;flex-wrap:wrap;gap:10px 14px;padding:14px 16px;align-items:center;border-top:1px solid #1d232c}
    .ui .spacer{flex:1 1 auto}
    .btn{appearance:none;border:1px solid #223;background:#10151b;color:var(--fg);padding:10px 14px;border-radius:12px;cursor:pointer;font-weight:600}
    .btn[disabled]{opacity:.5;cursor:not-allowed}
    .btn.primary{background:var(--accent);border-color:var(--accent);color:#0a0b0e}
    label{display:inline-flex;gap:8px;align-items:center;color:var(--muted)}
    input[type="range"]{width:180px}
    .status{color:var(--muted)}
  </style>
  <!-- MediaPipe Face Detection (UMD) -->
  <script defer src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection@0.4/face_detection.js"></script>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <div class="stage">
        <video id="video" playsinline muted></video>
        <canvas id="canvas"></canvas>
      </div>

      <div class="ui">
        <button id="startBtn" class="btn primary">Start camera</button>
        <button id="stopBtn" class="btn" disabled>Stop</button>
        <span class="spacer"></span>
        <label>Blur <input id="blurStrength" type="range" min="6" max="40" value="22" /></label>
        <label><input id="mirror" type="checkbox" checked /> Mirror</label>
        <label><input id="showBoxes" type="checkbox" /> Show boxes</label>
        <span class="spacer"></span>
        <span id="status" class="status">Idle</span>
      </div>
    </div>
  </div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const startBtn = document.getElementById('startBtn');
    const stopBtn  = document.getElementById('stopBtn');
    const blurStrength = document.getElementById('blurStrength');
    const mirror = document.getElementById('mirror');
    const showBoxes = document.getElementById('showBoxes');
    const statusEl = document.getElementById('status');

    let stream = null, rafId = null;
    let lastDetections = [];        // array of {x,y,width,height} in px
    let detTimer = 0, mpDetector = null, mpInFlight = false;
    const detectIntervalMs = 90, pad = 28;

    const blurCanvas = document.createElement('canvas');
    const blurCtx = blurCanvas.getContext('2d');

    const setStatus = (m) => statusEl.textContent = m;

    function fitCanvasToVideo() {
      const w = video.videoWidth || 1280, h = video.videoHeight || 720;
      canvas.width = w; canvas.height = h;
      blurCanvas.width = w; blurCanvas.height = h;
    }

    function mirrorX(x, width, totalWidth) {
      return totalWidth - (x + width);
    }

    function roundRectPath(c, x, y, w, h, r=22) {
      if (c.roundRect) { c.beginPath(); c.roundRect(x,y,w,h,r); return; }
      const rr = Math.min(r, w/2, h/2);
      c.beginPath();
      c.moveTo(x+rr,y);
      c.arcTo(x+w,y,x+w,y+h,rr);
      c.arcTo(x+w,y+h,x,y+h,rr);
      c.arcTo(x,y+h,x,y,rr);
      c.arcTo(x,y,x+w,y,rr);
      c.closePath();
    }

    async function initMediaPipe() {
      const ns = window.FaceDetection || window.faceDetection;
      if (!ns || !ns.FaceDetection) throw new Error('MediaPipe library failed to load.');
      mpDetector = new ns.FaceDetection({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection@0.4/${file}`
      });
      mpDetector.setOptions({ model: 'short', minDetectionConfidence: 0.6 });
      mpDetector.onResults((res) => {
        const w = canvas.width, h = canvas.height;
        lastDetections = (res.detections || []).map(d => {
          const bb = d.locationData.relativeBoundingBox;
          return {
            x: Math.max(0, bb.xMin * w),
            y: Math.max(0, bb.yMin * h),
            width: Math.min(w, bb.width * w),
            height: Math.min(h, bb.height * h)
          };
        });
      });
    }

    async function start() {
      try {
        setStatus('Requesting camera…');
        startBtn.disabled = true;

        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
        video.srcObject = stream;
        await new Promise(res => video.onloadedmetadata = res);
        await video.play();

        fitCanvasToVideo();
        window.addEventListener('resize', fitCanvasToVideo);

        await initMediaPipe();
        stopBtn.disabled = false;
        setStatus('Camera running. Detecting (MediaPipe)…');

        loop(performance.now());
      } catch (err) {
        console.error(err);
        setStatus('Error: ' + err.message);
        startBtn.disabled = false; stopBtn.disabled = true;
      }
    }

    function stop() {
      cancelAnimationFrame(rafId); rafId = null;
      if (stream) { stream.getTracks().forEach(t => t.stop()); stream = null; }
      mpDetector = null; lastDetections = [];
      ctx.clearRect(0,0,canvas.width,canvas.height);
      stopBtn.disabled = true; startBtn.disabled = false;
      setStatus('Stopped');
    }

    async function loop(now) {
      if (!stream) return;

      const w = canvas.width, h = canvas.height;

      // Draw current frame
      ctx.save();
      if (mirror.checked) { ctx.translate(w,0); ctx.scale(-1,1); }
      ctx.drawImage(video, 0, 0, w, h);
      ctx.restore();

      // Prepare blurred copy
      blurCtx.filter = `blur(${+blurStrength.value}px)`;
      blurCtx.drawImage(canvas, 0, 0, w, h);

      // Throttle detections
      if ((!detTimer || (now - detTimer) > detectIntervalMs) && mpDetector && !mpInFlight) {
        detTimer = now; mpInFlight = true;
        mpDetector.send({ image: video }).finally(() => mpInFlight = false);
      }

      // Paint blur on faces
      for (const box of lastDetections) {
        let x = box.x, y = box.y, bw = box.width, bh = box.height;
        if (mirror.checked) x = mirrorX(x, bw, w);
        x = Math.max(0, Math.floor(x - pad));
        y = Math.max(0, Math.floor(y - pad));
        bw = Math.min(w - x, Math.ceil(bw + pad*2));
        bh = Math.min(h - y, Math.ceil(bh + pad*2));

        ctx.save();
        roundRectPath(ctx, x, y, bw, bh, 22);
        ctx.clip();
        ctx.drawImage(blurCanvas, 0, 0);
        ctx.restore();

        if (showBoxes.checked) {
          ctx.save(); ctx.lineWidth = 2; ctx.strokeStyle = 'rgba(110,168,254,.9)';
          roundRectPath(ctx, x, y, bw, bh, 22); ctx.stroke(); ctx.restore();
        }
      }

      rafId = requestAnimationFrame(loop);
    }

    startBtn.addEventListener('click', start);
    stopBtn.addEventListener('click', stop);
    window.addEventListener('keydown', (e) => {
      if (e.code === 'Space') { e.preventDefault(); (stream ? stop : start)(); }
      else if (e.key.toLowerCase() === 'm') { mirror.checked = !mirror.checked; }
      else if (e.key.toLowerCase() === 'b') { showBoxes.checked = !showBoxes.checked; }
    });
  </script>
</body>
</html>
