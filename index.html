<!doctype html>
<html lang="en" class="dark">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>U N K N O W N // PREVIEW</title>

  <script src="https://cdn.tailwindcss.com"></script>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js" crossorigin="anonymous"></script>

  <style>
    body { 
        font-family: 'JetBrains Mono', monospace; 
        background-color: #000000;
        color: #EAEAEA;
    }
    .btn {
        border: 1px solid #555;
        transition: all 0.2s ease-in-out;
    }
    .btn:hover {
        background-color: #EAEAEA;
        color: #000;
        border-color: #EAEAEA;
    }
  </style>
</head>
<body class="bg-black">

  <div class="main-stage w-screen h-screen bg-black relative flex items-center justify-center overflow-hidden">
    <video id="video" playsinline muted class="hidden"></video>
    <video id="backgroundMedia" loop muted playsinline class="hidden absolute w-full h-full object-cover"></video>
    <img id="backgroundImage" class="hidden absolute w-full h-full object-cover" />
    <canvas id="glcanvas" class="w-full h-full object-cover"></canvas>
    <div id="startup" class="absolute inset-0 flex flex-col items-center justify-center bg-black/80 z-10">
        <h1 class="text-3xl font-bold text-white tracking-widest mb-2">U N K N O W N</h1>
        <p class="text-sm text-gray-400 font-mono mb-6">// PREVIEW</p>
        <button id="startBtn" class="btn font-bold py-2 px-8">Initialize Camera</button>
        <div id="msg" class="text-red-400 font-mono text-xs mt-4 h-4"></div>
    </div>
  </div>

  <script>
  (() => {
    // --- APP ARCHITECTURE REFACTORED FOR TWO WINDOWS ---
    // This window (index.html) is now ONLY the renderer.
    // It maintains the application state and listens for messages from controls.html.
    
    const vertSrc = `
      attribute vec2 a_pos;
      varying vec2 v_uv;
      void main() {
        v_uv = a_pos;
        gl_Position = vec4(a_pos * 2.0 - 1.0, 0.0, 1.0);
      }`;

    const fragSrc = `
      precision highp float;
      varying vec2 v_uv;
      uniform sampler2D u_tex, u_feedbackTex, u_maskTex, u_backgroundTex;
      uniform vec2 u_resolution;
      uniform float u_time;
      uniform bool u_isFeedbackPass, u_useBackground;
      uniform float u_maskFeather;
      uniform float u_overallOpacity, u_flickerPerSecond, u_flickerDuration, u_flickerIntensity, u_flickerFade;
      uniform float u_seepAmount, u_seepIntensity;
      uniform float u_feedbackAmount, u_feedbackZoom, u_glitchIntensity, u_glitchBlockSize, u_rgbShift, u_noiseAmount, u_noiseSpeed, u_vignette;
      uniform float u_globalSmearIntensity, u_globalSmearAngle, u_spotSmearIntensity, u_spotSmearDensity, u_spotSmearSize;
      
      float rand(vec2 co){ return fract(sin(dot(co.xy, vec2(12.9898, 78.233))) * 43758.5453); }
      vec4 smear(sampler2D tex, vec2 uv, float intensity, float angle) {
        vec2 dir = vec2(cos(angle), sin(angle)) / u_resolution;
        vec4 color = vec4(0.0);
        const int samples = 16;
        for (int i = 0; i < samples; i++) {
          float t = float(i) / float(samples - 1);
          color += texture2D(tex, uv - dir * t * intensity);
        }
        return color / float(samples);
      }
      vec4 blur(sampler2D tex, vec2 uv, float radius) {
          vec4 acc = vec4(0.0);
          vec2 res = u_resolution.xy;
          float count = 0.0;
          for(float x = -2.0; x <= 2.0; x++) {
              for(float y = -2.0; y <= 2.0; y++) {
                  vec2 offset = vec2(x, y) * radius / res;
                  acc += texture2D(tex, uv + offset);
                  count += 1.0;
              }
          }
          return acc / count;
      }
      void main() {
        vec2 uv = v_uv;
        vec4 videoColor = texture2D(u_tex, uv);
        vec4 feedbackColor = texture2D(u_feedbackTex, (uv - 0.5) * u_feedbackZoom + 0.5);
        vec4 effectedColor = mix(videoColor, feedbackColor, u_feedbackAmount);
        if (rand(vec2(floor(u_time * 15.0), 0.0)) < u_glitchIntensity) {
          vec2 block_uv = floor(uv * u_resolution.y / u_glitchBlockSize) / (u_resolution.y / u_glitchBlockSize);
          effectedColor = texture2D(u_tex, uv + vec2((rand(block_uv) - 0.5) * 0.1, 0.0));
        }
        float r = texture2D(u_tex, uv + vec2(u_rgbShift, 0.0)).r;
        float b = texture2D(u_tex, uv - vec2(u_rgbShift, 0.0)).b;
        effectedColor = vec4(r, effectedColor.g, b, effectedColor.a);
        effectedColor += (rand(uv + u_time * u_noiseSpeed) - 0.5) * u_noiseAmount;
        effectedColor.rgb *= 1.0 - u_vignette * distance(uv, vec2(0.5));
        vec4 smearedColor = effectedColor;
        vec2 grid_uv = floor(uv * u_spotSmearSize) / u_spotSmearSize;
        if (rand(grid_uv + floor(u_time * 5.0)) < u_spotSmearDensity) {
          smearedColor = smear(u_feedbackTex, uv, u_spotSmearIntensity, rand(grid_uv + 10.0) * 6.283);
        }
        float maskValue = texture2D(u_maskTex, uv).r;
        if (maskValue > 0.1) {
            vec4 globalSmear = smear(u_feedbackTex, uv, u_globalSmearIntensity, radians(u_globalSmearAngle));
            smearedColor = mix(smearedColor, globalSmear, 0.5);
        }
        float effectedGray = dot(smearedColor.rgb, vec3(0.299, 0.587, 0.114));
        vec4 effectedGrayscale = vec4(vec3(effectedGray), 1.0);
        if (u_isFeedbackPass) {
          gl_FragColor = effectedGrayscale;
          return;
        }
        float originalGray = dot(videoColor.rgb, vec3(0.299, 0.587, 0.114));
        vec4 originalGrayscale = vec4(vec3(originalGray), 1.0);
        float baseMask = texture2D(u_maskTex, uv).r;
        float blurredMask = blur(u_maskTex, uv, u_seepIntensity).r;
        float seep = (1.0 - baseMask) * blurredMask * u_seepAmount;
        float finalMask = smoothstep(0.5 - u_maskFeather, 0.5 + u_maskFeather, baseMask);
        float silhouetteMask = clamp(finalMask + seep, 0.0, 1.0);
        float flickerMultiplier = 1.0;
        if (u_flickerPerSecond > 0.0) {
            float flickerCycle = 1.0 / u_flickerPerSecond;
            float flickerPhase = mod(u_time, flickerCycle);
            float flickerEdge = flickerCycle * u_flickerDuration;
            float fadeWidth = flickerCycle * u_flickerFade * 0.5;
            float isFlickerOff = 1.0 - smoothstep(flickerEdge - fadeWidth, flickerEdge + fadeWidth, flickerPhase);
            flickerMultiplier = 1.0 - (isFlickerOff * u_flickerIntensity);
        }
        float effectAmount = u_overallOpacity * flickerMultiplier;
        vec4 foregroundColor = mix(originalGrayscale, effectedGrayscale, effectAmount);
        vec4 backgroundColor = u_useBackground ? texture2D(u_backgroundTex, uv) : originalGrayscale;
        gl_FragColor = mix(backgroundColor, foregroundColor, silhouetteMask);
      }`;

    const Renderer = {
      gl: null, program: null, textures: {}, framebuffers: {}, uniforms: {},
      maskCanvas: document.createElement('canvas'),
      init(canvas, vsSrc, fsSrc, uniformKeys) {
        this.gl = canvas.getContext('webgl', { premultipliedAlpha: false, antialias: true });
        if (!this.gl) throw new Error('WebGL not available');
        const compile = (type, src) => { const s = this.gl.createShader(type); this.gl.shaderSource(s, src); this.gl.compileShader(s); if (!this.gl.getShaderParameter(s, this.gl.COMPILE_STATUS)) throw new Error(`Shader compile error: ${this.gl.getShaderInfoLog(s)}`); return s; };
        this.program = this.gl.createProgram(); this.gl.attachShader(this.program, compile(this.gl.VERTEX_SHADER, vsSrc)); this.gl.attachShader(this.program, compile(this.gl.FRAGMENT_SHADER, fsSrc)); this.gl.linkProgram(this.program); if (!this.gl.getProgramParameter(this.program, this.gl.LINK_STATUS)) throw new Error(`Program link error: ${this.gl.getProgramInfoLog(this.program)}`);
        const buffer = this.gl.createBuffer(); this.gl.bindBuffer(this.gl.ARRAY_BUFFER, buffer); this.gl.bufferData(this.gl.ARRAY_BUFFER, new Float32Array([0,0, 1,0, 0,1, 1,1]), this.gl.STATIC_DRAW);
        const posLoc = this.gl.getAttribLocation(this.program, 'a_pos'); this.gl.enableVertexAttribArray(posLoc); this.gl.vertexAttribPointer(posLoc, 2, this.gl.FLOAT, false, 0, 0);
        const createTex = () => { const tex = this.gl.createTexture(); this.gl.bindTexture(this.gl.TEXTURE_2D, tex); this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE); this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE); this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR); this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR); return tex; };
        this.textures = { video: createTex(), feedbackA: createTex(), feedbackB: createTex(), mask: createTex(), background: createTex() };
        this.framebuffers.feedback = this.gl.createFramebuffer();
        this.gl.useProgram(this.program);
        uniformKeys.forEach(key => this.uniforms[key] = this.gl.getUniformLocation(this.program, key));
      },
      fit(video) {
        if (!video.videoWidth) return;
        const { videoWidth: w, videoHeight: h } = video;
        const canvas = this.gl.canvas;
        if (canvas.width === w && canvas.height === h) return;
        canvas.width = w; canvas.height = h;
        const resizableTextures = [this.textures.video, this.textures.feedbackA, this.textures.feedbackB, this.textures.mask];
        resizableTextures.forEach(tex => { this.gl.bindTexture(this.gl.TEXTURE_2D, tex); this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, w, h, 0, this.gl.RGBA, this.gl.UNSIGNED_BYTE, null); });
        this.gl.viewport(0, 0, w, h);
      },
      drawMask(video, segmentationMask) {
        const { videoWidth: W, videoHeight: H } = video;
        const ctx = this.maskCanvas.getContext('2d');
        if (this.maskCanvas.width !== W || this.maskCanvas.height !== H) { this.maskCanvas.width = W; this.maskCanvas.height = H; }
        ctx.fillStyle = 'black'; ctx.fillRect(0, 0, W, H);
        if (segmentationMask) ctx.drawImage(segmentationMask, 0, 0, W, H);
        this.gl.activeTexture(this.gl.TEXTURE2); this.gl.bindTexture(this.gl.TEXTURE_2D, this.textures.mask);
        this.gl.pixelStorei(this.gl.UNPACK_FLIP_Y_WEBGL, true);
        this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, this.maskCanvas);
      },
      render(appState) {
        const { video, t, uniforms, backgroundMedia } = appState;
        this.gl.useProgram(this.program);
        this.gl.activeTexture(this.gl.TEXTURE0); this.gl.bindTexture(this.gl.TEXTURE_2D, this.textures.video);
        this.gl.pixelStorei(this.gl.UNPACK_FLIP_Y_WEBGL, true); this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, video);
        if (uniforms.u_useBackground && (backgroundMedia.videoWidth || backgroundMedia.naturalWidth || backgroundMedia.width)) {
            this.gl.activeTexture(this.gl.TEXTURE3); this.gl.bindTexture(this.gl.TEXTURE_2D, this.textures.background);
            this.gl.pixelStorei(this.gl.UNPACK_FLIP_Y_WEBGL, true); this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, backgroundMedia);
        }
        this.gl.uniform2f(this.uniforms.u_resolution, this.gl.canvas.width, this.gl.canvas.height);
        this.gl.uniform1f(this.uniforms.u_time, t);
        for(const key in uniforms) { this.gl.uniform1f(this.uniforms[key], uniforms[key]); }
        this.gl.uniform1i(this.uniforms.u_tex, 0); this.gl.uniform1i(this.uniforms.u_feedbackTex, 1);
        this.gl.uniform1i(this.uniforms.u_maskTex, 2); this.gl.uniform1i(this.uniforms.u_backgroundTex, 3);
        this.gl.activeTexture(this.gl.TEXTURE1); this.gl.bindTexture(this.gl.TEXTURE_2D, this.textures.feedbackA);
        this.gl.uniform1i(this.uniforms.u_isFeedbackPass, 1); this.gl.bindFramebuffer(this.gl.FRAMEBUFFER, this.framebuffers.feedback);
        this.gl.framebufferTexture2D(this.gl.FRAMEBUFFER, this.gl.COLOR_ATTACHMENT0, this.gl.TEXTURE_2D, this.textures.feedbackB, 0);
        this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);
        this.gl.uniform1i(this.uniforms.u_isFeedbackPass, 0); this.gl.bindFramebuffer(this.gl.FRAMEBUFFER, null);
        this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);
        [this.textures.feedbackA, this.textures.feedbackB] = [this.textures.feedbackB, this.textures.feedbackA];
      }
    };

    const BodySegmenter = {
      segmenter: null, lastResult: null, isReady: false, isBusy: false, lastUpdateTime: 0, minInterval: 60,
      async init() {
        if (this.isReady) return true;
        try {
          this.segmenter = new window.SelfieSegmentation({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}` });
          this.segmenter.setOptions({ modelSelection: 1 });
          this.segmenter.onResults(res => { this.lastResult = res.segmentationMask; this.isBusy = false; });
          await this.segmenter.initialize();
          this.isReady = true; return true;
        } catch (err) { console.error("Selfie Segmentation init failed:", err); return false; }
      },
      update(video) {
        const now = performance.now();
        if (this.isReady && !this.isBusy && (now - this.lastUpdateTime) > this.minInterval) {
          this.isBusy = true; this.lastUpdateTime = now; this.segmenter.send({ image: video });
        }
      }
    };

    const App = {
      stream: null, rafId: null,
      elements: {},
      appState: {
        uniforms: {
          u_feedbackAmount: 0.97, u_feedbackZoom: 1.001, u_glitchIntensity: 0.1, u_glitchBlockSize: 8, u_rgbShift: 0.01,
          u_noiseAmount: 0.05, u_noiseSpeed: 1, u_vignette: 0.5,
          u_globalSmearIntensity: 30, u_globalSmearAngle: 0, u_spotSmearIntensity: 10, u_spotSmearDensity: 0.2, u_spotSmearSize: 20,
          u_overallOpacity: 1.0, u_flickerPerSecond: 1.0, u_flickerDuration: 0.01, u_flickerIntensity: 1.0, u_flickerFade: 0.3,
          u_seepAmount: 2.0, u_seepIntensity: 20, u_maskFeather: 0.15,
          u_useBackground: 0,
        },
        settings: {
          animate: true,
          mirror: true
        },
        jitter: {
          base: {}, current: {}, amount: 0.005, speed: 2.5, active: true
        }
      },

      async start() {
        if (!navigator.mediaDevices?.getUserMedia) return this.setMsg('getUserMedia not supported.');
        try {
          this.setMsg('Requesting camera...');
          this.stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user', width: 1280, height: 720 }, audio: false });
          this.elements.video.srcObject = this.stream;
          await new Promise(resolve => { this.elements.video.onloadedmetadata = resolve; });
          await this.elements.video.play();

          this.setMsg('Initializing GL...');
          const uniformKeys = ['u_resolution', 'u_time', 'u_isFeedbackPass', 'u_tex', 'u_feedbackTex', 'u_maskTex', 'u_backgroundTex', ...Object.keys(this.appState.uniforms)];
          Renderer.init(this.elements.glcanvas, vertSrc, fragSrc, uniformKeys);
          Renderer.fit(this.elements.video);

          this.setMsg('Initializing Body Segmentation...');
          if (!(await BodySegmenter.init())) { this.setMsg('Segmentation Failed'); return; }
          
          this.elements.startup.style.display = 'none';
          this.setMsg('');
          
          // Open controls window
          window.open('controls.html', 'controls', 'width=450,height=900,menubar=no,toolbar=no,location=no,status=no');
          this.loop();
        } catch (err) {
          console.error(err);
          this.setMsg(`Camera error: ${(err.name === 'NotAllowedError') ? 'Permission denied.' : err.message}`);
        }
      },
      
      loop(time) {
        this.rafId = requestAnimationFrame(t => this.loop(t));
        const video = this.elements.video;
        if (!video.videoWidth || !Renderer.gl) return;
        
        Renderer.fit(video);
        BodySegmenter.update(video);
        Renderer.drawMask(video, BodySegmenter.lastResult);
        
        const t = this.appState.settings.animate ? time / 1000 : 0;
        
        let uniformsToRender = {...this.appState.uniforms};
        // Apply jitter
        if (this.appState.jitter.active) {
            const { jitter } = this.appState;
            for(const key in jitter.base) {
                const baseVal = jitter.base[key];
                const offset = (Math.sin(t * jitter.speed + key.length) * Math.cos(t * jitter.speed * 0.7 + key.length)) * jitter.amount * 1.0; // Assume range of 1 for simplicity
                uniformsToRender[key] = Math.max(0, baseVal + offset);
            }
        }
        
        const backgroundEl = !this.elements.backgroundImage.classList.contains('hidden') ? this.elements.backgroundImage : this.elements.backgroundMedia;

        Renderer.render({
          video: video, t: t, uniforms: uniformsToRender, backgroundMedia: backgroundEl
        });
      },

      handleMessage(event) {
        const { type, payload } = event.data;
        switch (type) {
            case 'UPDATE_UNIFORM':
                if (this.appState.uniforms.hasOwnProperty(payload.key)) {
                    this.appState.uniforms[payload.key] = payload.value;
                }
                break;
            case 'UPDATE_SETTING':
                 if (this.appState.settings.hasOwnProperty(payload.key)) {
                    this.appState.settings[payload.key] = payload.value;
                    if(payload.key === 'mirror') {
                        this.elements.glcanvas.style.transform = payload.value ? 'scaleX(-1)' : 'none';
                    }
                }
                break;
            case 'UPDATE_JITTER':
                if (this.appState.jitter.hasOwnProperty(payload.key)) {
                    this.appState.jitter[payload.key] = payload.value;
                }
                break;
            case 'LOAD_PRESET':
                // Update all uniforms from preset
                for(const key in payload.uniforms) {
                    if (this.appState.uniforms.hasOwnProperty(key)) {
                        this.appState.uniforms[key] = payload.uniforms[key];
                    }
                }
                // Update settings
                 for(const key in payload.settings) {
                    if (this.appState.settings.hasOwnProperty(key)) {
                        this.appState.settings[key] = payload.settings[key];
                    }
                }
                // Update jitter
                this.appState.jitter.active = payload.jitter.active;
                this.appState.jitter.amount = payload.jitter.amount;
                this.appState.jitter.speed = payload.jitter.speed;
                // Update jitter base values
                this.appState.jitter.base = { ...payload.uniforms };
                break;
            case 'UPDATE_JITTER_BASE':
                 this.appState.jitter.base = { ...payload };
                 break;
            case 'SET_BACKGROUND':
                const url = payload.url;
                if (payload.fileType.startsWith('image/')) {
                    this.elements.backgroundImage.src = url;
                    this.elements.backgroundImage.classList.remove('hidden');
                    this.elements.backgroundMedia.classList.add('hidden');
                    this.elements.backgroundMedia.pause();
                } else if (payload.fileType.startsWith('video/')) {
                    this.elements.backgroundMedia.src = url;
                    this.elements.backgroundMedia.play();
                    this.elements.backgroundMedia.classList.remove('hidden');
                    this.elements.backgroundImage.classList.add('hidden');
                }
                this.appState.uniforms.u_useBackground = payload.useBg ? 1.0 : 0.0;
                break;
        }
      },

      setMsg(text) { this.elements.msg.textContent = text; },

      init() {
        this.elements = {
            video: document.getElementById('video'),
            glcanvas: document.getElementById('glcanvas'),
            startBtn: document.getElementById('startBtn'),
            msg: document.getElementById('msg'),
            startup: document.getElementById('startup'),
            backgroundMedia: document.getElementById('backgroundMedia'),
            backgroundImage: document.getElementById('backgroundImage'),
        };
        // Store base values for jitter calculation
        this.appState.jitter.base = {...this.appState.uniforms};
        
        this.elements.startBtn.addEventListener('click', () => this.start());
        window.addEventListener('message', (e) => this.handleMessage(e));
        // Apply initial mirror setting
        this.elements.glcanvas.style.transform = this.appState.settings.mirror ? 'scaleX(-1)' : 'none';
      }
    };
    
    App.init();
  })();
  </script>

</body>
</html>
