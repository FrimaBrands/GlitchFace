<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Webcam Face Blur</title>
  <style>
    :root {
      --bg: #0f1115;
      --fg: #e5e7eb;
      --muted: #9aa0aa;
      --accent: #6ee7b7;
      --danger: #f87171;
    }
    html, body { height: 100%; }
    body {
      margin: 0; background: var(--bg); color: var(--fg);
      font: 15px/1.5 system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Arial, "Apple Color Emoji", "Segoe UI Emoji";
      display: grid; place-items: center;
    }
    .wrap { width: min(960px, 96vw); }
    .panel {
      background: #11141a; border: 1px solid #1f2430; border-radius: 16px; padding: 16px; box-shadow: 0 8px 30px rgba(0,0,0,.35);
    }
    header { display: flex; align-items: center; justify-content: space-between; gap: 12px; margin-bottom: 12px; }
    h1 { font-size: 18px; margin: 0; letter-spacing: .2px; }
    .controls { display: flex; flex-wrap: wrap; gap: 8px; align-items: center; }
    button, select, .badge {
      background: #0b0e13; color: var(--fg); border: 1px solid #1f2430; border-radius: 12px; padding: 8px 12px; cursor: pointer;
    }
    button:hover { border-color: #2e3748; }
    button:disabled { opacity: .6; cursor: not-allowed; }
    .badge { font-size: 12px; }
    #stage { position: relative; aspect-ratio: 16/9; background: #0c1016; border-radius: 16px; overflow: hidden; }
    #canvas { display: block; width: 100%; height: 100%; }
    #video { display: none; }
    .note { color: var(--muted); margin-top: 10px; font-size: 13px; }
    .error { color: var(--danger); }
    footer { margin-top: 12px; display: flex; justify-content: space-between; align-items: center; color: var(--muted); font-size: 12px; }
    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="panel">
      <header>
        <h1>Webcam Face Blur</h1>
        <div class="controls">
          <button id="startBtn">Start camera</button>
          <button id="stopBtn" disabled>Stop</button>
          <label class="badge"><input type="checkbox" id="mirrorChk" checked> Mirror</label>
          <span id="status" class="badge">Idle</span>
        </div>
      </header>
      <div id="stage">
        <video id="video" playsinline muted></video>
        <canvas id="canvas" aria-label="camera with face blur"></canvas>
      </div>
      <div id="msg" class="note"></div>
      <footer>
        <span>Runs entirely in your browser. HTTPS required for camera access.</span>
        <span>Built for Chrome; uses the Shape Detection <code>FaceDetector</code> API.</span>
      </footer>
    </div>
  </div>

<script>
(() => {
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const ctx = canvas.getContext('2d', { willReadFrequently: false });
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const mirrorChk = document.getElementById('mirrorChk');
  const statusEl = document.getElementById('status');
  const msgEl = document.getElementById('msg');

  let stream = null;
  let rafId = null;
  let detector = null;
  let lastDetections = [];
  let lastDetTime = 0;
  const DETECT_EVERY_MS = 120; // run face detection ~8 FPS for performance

  const faceApiAvailable = 'FaceDetector' in window;

  function setStatus(text) { statusEl.textContent = text; }
  function setMsg(text, isError=false) {
    msgEl.textContent = text || '';
    msgEl.classList.toggle('error', !!isError);
  }

  function fitCanvasToVideo() {
    if (!video.videoWidth) return;
    const w = video.videoWidth;
    const h = video.videoHeight;
    canvas.width = w;
    canvas.height = h;
  }

  async function initDetector() {
    if (!faceApiAvailable) throw new Error('FaceDetector API not available in this browser.');
    detector = new FaceDetector({ fastMode: true, maxDetectedFaces: 5 });
  }

  async function start() {
    if (!navigator.mediaDevices?.getUserMedia) {
      setMsg('getUserMedia is not supported in this browser. Try Chrome, Edge, or a modern browser.', true);
      return;
    }

    try {
      setStatus('Requesting camera...');
      stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
      video.srcObject = stream;
      await video.play();
      fitCanvasToVideo();
      window.addEventListener('resize', fitCanvasToVideo);

      // Initialize detector (or tell the user if missing)
      try {
        await initDetector();
        setMsg('');
      } catch (e) {
        console.warn(e);
        setMsg('FaceDetector API not available. Use Chrome (latest) and make sure "Experimental Web Platform features" are enabled, or ask me for a MediaPipe fallback.', true);
      }

      startBtn.disabled = true;
      stopBtn.disabled = false;
      loop();
    } catch (err) {
      console.error(err);
      const httpsHint = location.protocol !== 'https:' ? ' • Tip: GitHub Pages serves over HTTPS; local files or insecure HTTP will block the camera.' : '';
      setMsg('Could not start camera: ' + err.message + httpsHint, true);
      setStatus('Error');
    }
  }

  function stop() {
    if (rafId) cancelAnimationFrame(rafId), rafId = null;
    if (stream) {
      stream.getTracks().forEach(t => t.stop());
      stream = null;
    }
    startBtn.disabled = false;
    stopBtn.disabled = true;
    setStatus('Stopped');
  }

  function drawFrame() {
    if (!video.videoWidth) return;

    const w = canvas.width;
    const h = canvas.height;

    ctx.save();
    // Mirror if requested
    if (mirrorChk.checked) {
      ctx.translate(w, 0);
      ctx.scale(-1, 1);
    }

    // Draw the base video frame
    ctx.drawImage(video, 0, 0, w, h);

    // Overlay blurred patches where faces are
    if (lastDetections && lastDetections.length) {
      for (const face of lastDetections) {
        const { x, y, width, height } = face.boundingBox || face.boundingBox || face; // be liberal

        // Grow the blur box a bit to cover hair/edges
        const grow = Math.round(Math.max(width, height) * 0.15);
        const bx = Math.max(0, x - grow);
        const by = Math.max(0, y - grow);
        const bw = Math.min(w - bx, width + 2*grow);
        const bh = Math.min(h - by, height + 2*grow);

        // Clip to a rounded rectangle so blur looks nicer
        const r = Math.floor(Math.min(bw, bh) * 0.12);
        roundedRect(ctx, bx, by, bw, bh, r);
        ctx.clip();

        // Draw the same region with a blur filter
        ctx.filter = 'blur(22px)';
        ctx.drawImage(video, bx, by, bw, bh, bx, by, bw, bh);

        ctx.filter = 'none';
        ctx.beginPath(); // reset clip
        ctx.restore();
        ctx.save();
        if (mirrorChk.checked) { ctx.translate(w, 0); ctx.scale(-1, 1); }
      }
    }

    ctx.restore();
  }

  function roundedRect(ctx, x, y, w, h, r) {
    ctx.beginPath();
    ctx.moveTo(x + r, y);
    ctx.arcTo(x + w, y, x + w, y + h, r);
    ctx.arcTo(x + w, y + h, x, y + h, r);
    ctx.arcTo(x, y + h, x, y, r);
    ctx.arcTo(x, y, x + w, y, r);
    ctx.closePath();
  }

  async function detectFaces(now) {
    if (!detector) return [];
    try {
      const faces = await detector.detect(video);
      // FaceDetector returns an array of {boundingBox: {x,y,width,height}, landmarks:[...]}
      return faces || [];
    } catch (e) {
      // Detection can fail sporadically between frames; swallow and keep going
      return [];
    }
  }

  async function loop(now) {
    rafId = requestAnimationFrame(loop);

    // Draw current frame
    drawFrame();

    // Throttle detection
    if (!lastDetTime || (performance.now() - lastDetTime) > DETECT_EVERY_MS) {
      lastDetTime = performance.now();
      if (detector) {
        setStatus('Detecting…');
        detectFaces().then(faces => {
          lastDetections = faces.map(f => ({ boundingBox: f.boundingBox }));
          setStatus(faces.length ? `Faces: ${faces.length}` : 'No face');
        });
      } else {
        setStatus('Camera on');
      }
    }
  }

  startBtn.addEventListener('click', start);
  stopBtn.addEventListener('click', stop);

  // Auto-start if permissions are already granted
  (async () => {
    try {
      const p = await navigator.permissions.query({ name: 'camera' });
      if (p.state === 'granted') start();
    } catch {}
  })();
})();
</script>
</body>
</html>
