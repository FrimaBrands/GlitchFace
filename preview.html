<!doctype html>
<html lang="en" class="dark">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>U N K N O W N // Preview</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js" crossorigin="anonymous"></script>
  <style>
    body { background-color: #000000; margin: 0; overflow: hidden; }
    .main-stage { width: 100vw; height: 100vh; display: flex; align-items: center; justify-content: center; }
    #glcanvas { width: 100%; height: 100%; object-fit: contain; }
  </style>
</head>
<body>
  <div class="main-stage">
    <video id="video" playsinline muted class="hidden"></video>
    <video id="backgroundMedia" loop muted playsinline class="hidden absolute w-full h-full object-cover"></video>
    <img id="backgroundImage" class="hidden absolute w-full h-full object-cover" />
    <canvas id="glcanvas"></canvas>
  </div>

  <script>
  // --- All JavaScript functionality remains unchanged, but is now refactored for inter-window communication. ---
  (() => {
    // This preview window is now a "dumb" client. It receives state updates
    // from the controls window and uses them to render the visuals.
    // It sends status updates (like 'BODY DETECTED') back to the controls window.

    const channel = new BroadcastChannel('unknown_signal_processor');
    let currentState = {}; // This will hold the latest state from the controls window.

    const DOM = {
        video: document.getElementById('video'),
        glcanvas: document.getElementById('glcanvas'),
        backgroundMedia: document.getElementById('backgroundMedia'),
        backgroundImage: document.getElementById('backgroundImage'),
    };
    
    // --- VERTEX AND FRAGMENT SHADERS (Unchanged) ---
    const vertSrc = `attribute vec2 a_pos; varying vec2 v_uv; void main() { v_uv = a_pos; gl_Position = vec4(a_pos * 2.0 - 1.0, 0.0, 1.0); }`;
    const fragSrc = `precision highp float; varying vec2 v_uv; uniform sampler2D u_tex; uniform sampler2D u_feedbackTex; uniform sampler2D u_maskTex; uniform sampler2D u_backgroundTex; uniform vec2 u_resolution; uniform float u_time; uniform bool u_isFeedbackPass; uniform bool u_useBackground; uniform float u_maskFeather; uniform float u_overallOpacity; uniform float u_flickerPerSecond; uniform float u_flickerDuration; uniform float u_flickerIntensity; uniform float u_flickerFade; uniform float u_seepAmount; uniform float u_seepIntensity; uniform float u_feedbackAmount; uniform float u_feedbackZoom; uniform float u_glitchIntensity; uniform float u_glitchBlockSize; uniform float u_rgbShift; uniform float u_noiseAmount; uniform float u_noiseSpeed; uniform float u_vignette; uniform float u_globalSmearIntensity; uniform float u_globalSmearAngle; uniform float u_spotSmearIntensity; uniform float u_spotSmearDensity; uniform float u_spotSmearSize; float rand(vec2 co){ return fract(sin(dot(co.xy, vec2(12.9898, 78.233))) * 43758.5453); } vec4 smear(sampler2D tex, vec2 uv, float intensity, float angle) { vec2 dir = vec2(cos(angle), sin(angle)) / u_resolution; vec4 color = vec4(0.0); const int samples = 16; for (int i = 0; i < samples; i++) { float t = float(i) / float(samples - 1); color += texture2D(tex, uv - dir * t * intensity); } return color / float(samples); } vec4 blur(sampler2D tex, vec2 uv, float radius) { vec4 acc = vec4(0.0); vec2 res = u_resolution.xy; float count = 0.0; for(float x = -2.0; x <= 2.0; x++) { for(float y = -2.0; y <= 2.0; y++) { vec2 offset = vec2(x, y) * radius / res; acc += texture2D(tex, uv + offset); count += 1.0; } } return acc / count; } void main() { vec2 uv = v_uv; vec4 videoColor = texture2D(u_tex, uv); vec4 feedbackColor = texture2D(u_feedbackTex, (uv - 0.5) * u_feedbackZoom + 0.5); vec4 effectedColor = mix(videoColor, feedbackColor, u_feedbackAmount); if (rand(vec2(floor(u_time * 15.0), 0.0)) < u_glitchIntensity) { vec2 block_uv = floor(uv * u_resolution.y / u_glitchBlockSize) / (u_resolution.y / u_glitchBlockSize); effectedColor = texture2D(u_tex, uv + vec2((rand(block_uv) - 0.5) * 0.1, 0.0)); } float r = texture2D(u_tex, uv + vec2(u_rgbShift, 0.0)).r; float b = texture2D(u_tex, uv - vec2(u_rgbShift, 0.0)).b; effectedColor = vec4(r, effectedColor.g, b, effectedColor.a); effectedColor += (rand(uv + u_time * u_noiseSpeed) - 0.5) * u_noiseAmount; effectedColor.rgb *= 1.0 - u_vignette * distance(uv, vec2(0.5)); vec4 smearedColor = effectedColor; vec2 grid_uv = floor(uv * u_spotSmearSize) / u_spotSmearSize; if (rand(grid_uv + floor(u_time * 5.0)) < u_spotSmearDensity) { smearedColor = smear(u_feedbackTex, uv, u_spotSmearIntensity, rand(grid_uv + 10.0) * 6.283); } float maskValue = texture2D(u_maskTex, uv).r; if (maskValue > 0.1) { vec4 globalSmear = smear(u_feedbackTex, uv, u_globalSmearIntensity, radians(u_globalSmearAngle)); smearedColor = mix(smearedColor, globalSmear, 0.5); } float effectedGray = dot(smearedColor.rgb, vec3(0.299, 0.587, 0.114)); vec4 effectedGrayscale = vec4(vec3(effectedGray), 1.0); if (u_isFeedbackPass) { gl_FragColor = effectedGrayscale; return; } float originalGray = dot(videoColor.rgb, vec3(0.299, 0.587, 0.114)); vec4 originalGrayscale = vec4(vec3(originalGray), 1.0); float baseMask = texture2D(u_maskTex, uv).r; float blurredMask = blur(u_maskTex, uv, u_seepIntensity).r; float seep = (1.0 - baseMask) * blurredMask * u_seepAmount; float finalMask = smoothstep(0.5 - u_maskFeather, 0.5 + u_maskFeather, baseMask); float silhouetteMask = clamp(finalMask + seep, 0.0, 1.0); float flickerMultiplier = 1.0; if (u_flickerPerSecond > 0.0) { float flickerCycle = 1.0 / u_flickerPerSecond; float flickerPhase = mod(u_time, flickerCycle); float flickerEdge = flickerCycle * u_flickerDuration; float fadeWidth = flickerCycle * u_flickerFade * 0.5; float isFlickerOff = 1.0 - smoothstep(flickerEdge - fadeWidth, flickerEdge + fadeWidth, flickerPhase); flickerMultiplier = 1.0 - (isFlickerOff * u_flickerIntensity); } float effectAmount = u_overallOpacity * flickerMultiplier; vec4 foregroundColor = mix(originalGrayscale, effectedGrayscale, effectAmount); vec4 backgroundColor = u_useBackground ? texture2D(u_backgroundTex, uv) : originalGrayscale; gl_FragColor = mix(backgroundColor, foregroundColor, silhouetteMask); }`;

    const Renderer = { /* ... Full, unchanged Renderer object ... */ 
      gl: null, program: null, textures: {}, framebuffers: {}, uniforms: {}, maskCanvas: document.createElement('canvas'),
      init(canvas, vsSrc, fsSrc, uniformKeys) { this.gl = canvas.getContext('webgl', { premultipliedAlpha: false, antialias: true }); if (!this.gl) throw new Error('WebGL not available'); const compile = (type, src) => { const s = this.gl.createShader(type); this.gl.shaderSource(s, src); this.gl.compileShader(s); if (!this.gl.getShaderParameter(s, this.gl.COMPILE_STATUS)) throw new Error(`Shader compile error: ${this.gl.getShaderInfoLog(s)}`); return s; }; this.program = this.gl.createProgram(); this.gl.attachShader(this.program, compile(this.gl.VERTEX_SHADER, vsSrc)); this.gl.attachShader(this.program, compile(this.gl.FRAGMENT_SHADER, fsSrc)); this.gl.linkProgram(this.program); if (!this.gl.getProgramParameter(this.program, this.gl.LINK_STATUS)) throw new Error(`Program link error: ${this.gl.getProgramInfoLog(this.program)}`); const buffer = this.gl.createBuffer(); this.gl.bindBuffer(this.gl.ARRAY_BUFFER, buffer); this.gl.bufferData(this.gl.ARRAY_BUFFER, new Float32Array([0,0, 1,0, 0,1, 1,1]), this.gl.STATIC_DRAW); const posLoc = this.gl.getAttribLocation(this.program, 'a_pos'); this.gl.enableVertexAttribArray(posLoc); this.gl.vertexAttribPointer(posLoc, 2, this.gl.FLOAT, false, 0, 0); const createTex = () => { const tex = this.gl.createTexture(); this.gl.bindTexture(this.gl.TEXTURE_2D, tex); this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE); this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE); this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR); this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR); return tex; }; this.textures = { video: createTex(), feedbackA: createTex(), feedbackB: createTex(), mask: createTex(), background: createTex() }; this.framebuffers.feedback = this.gl.createFramebuffer(); this.gl.useProgram(this.program); uniformKeys.forEach(key => this.uniforms[key] = this.gl.getUniformLocation(this.program, key)); },
      fit(video) { if (!video.videoWidth) return; const { videoWidth: w, videoHeight: h } = video; const canvas = this.gl.canvas; if (canvas.width === w && canvas.height === h) return; canvas.width = w; canvas.height = h; const resizableTextures = [this.textures.video, this.textures.feedbackA, this.textures.feedbackB, this.textures.mask]; for (const tex of resizableTextures) { this.gl.bindTexture(this.gl.TEXTURE_2D, tex); this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, w, h, 0, this.gl.RGBA, this.gl.UNSIGNED_BYTE, null); } this.gl.viewport(0, 0, w, h); },
      drawMask(video, segmentationMask) { const { videoWidth: W, videoHeight: H } = video; const ctx = this.maskCanvas.getContext('2d'); if (this.maskCanvas.width !== W || this.maskCanvas.height !== H) { this.maskCanvas.width = W; this.maskCanvas.height = H; } ctx.fillStyle = 'black'; ctx.fillRect(0, 0, W, H); if (segmentationMask) { ctx.drawImage(segmentationMask, 0, 0, W, H); } this.gl.activeTexture(this.gl.TEXTURE2); this.gl.bindTexture(this.gl.TEXTURE_2D, this.textures.mask); this.gl.pixelStorei(this.gl.UNPACK_FLIP_Y_WEBGL, true); this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, this.maskCanvas); },
      render(appState) { const { video, t, state, backgroundMedia, useBg, maskFeather } = appState; if (!state || !state.controls) return; this.gl.useProgram(this.program); this.gl.activeTexture(this.gl.TEXTURE0); this.gl.bindTexture(this.gl.TEXTURE_2D, this.textures.video); this.gl.pixelStorei(this.gl.UNPACK_FLIP_Y_WEBGL, true); this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, video); if (useBg && (backgroundMedia.videoWidth || backgroundMedia.naturalWidth || backgroundMedia.width)) { this.gl.activeTexture(this.gl.TEXTURE3); this.gl.bindTexture(this.gl.TEXTURE_2D, this.textures.background); this.gl.pixelStorei(this.gl.UNPACK_FLIP_Y_WEBGL, true); this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, backgroundMedia); } this.gl.uniform2f(this.uniforms.u_resolution, this.gl.canvas.width, this.gl.canvas.height); this.gl.uniform1f(this.uniforms.u_time, t); const getVal = (group, key, neutral) => { const g = state.controls[group]; return (state.toggles[group] && g && g[key]) ? parseFloat(g[key]) : neutral; }; const getGlobalVal = (group, key) => { const g = state.globalControls[group]; return (g && g[key]) ? parseFloat(g[key]) : 0; }; this.gl.uniform1f(this.uniforms.u_feedbackAmount, getVal('Feedback', 'feedbackAmount', 0.0)); this.gl.uniform1f(this.uniforms.u_feedbackZoom, getVal('Feedback', 'feedbackZoom', 1.0)); this.gl.uniform1f(this.uniforms.u_glitchIntensity, getVal('Glitch', 'glitchIntensity', 0.0)); this.gl.uniform1f(this.uniforms.u_glitchBlockSize, getVal('Glitch', 'glitchBlockSize', 0.0)); this.gl.uniform1f(this.uniforms.u_rgbShift, getVal('Color', 'rgbShift', 0.0)); this.gl.uniform1f(this.uniforms.u_noiseAmount, getVal('Distortion', 'noiseAmount', 0.0)); this.gl.uniform1f(this.uniforms.u_noiseSpeed, getVal('Distortion', 'noiseSpeed', 0.0)); this.gl.uniform1f(this.uniforms.u_vignette, getVal('Distortion', 'vignette', 0.0)); this.gl.uniform1f(this.uniforms.u_globalSmearIntensity, getVal('Smear', 'globalSmearIntensity', 0.0)); this.gl.uniform1f(this.uniforms.u_globalSmearAngle, getVal('Smear', 'globalSmearAngle', 0.0)); this.gl.uniform1f(this.uniforms.u_spotSmearIntensity, getVal('Smear', 'spotSmearIntensity', 0.0)); this.gl.uniform1f(this.uniforms.u_spotSmearDensity, getVal('Smear', 'spotSmearDensity', 0.0)); this.gl.uniform1f(this.uniforms.u_spotSmearSize, getVal('Smear', 'spotSmearSize', 0.0)); this.gl.uniform1f(this.uniforms.u_overallOpacity, getGlobalVal('Opacity', 'overallOpacity')); this.gl.uniform1f(this.uniforms.u_flickerPerSecond, getGlobalVal('Opacity', 'flickerPerSecond')); this.gl.uniform1f(this.uniforms.u_flickerDuration, getGlobalVal('Opacity', 'flickerDuration')); this.gl.uniform1f(this.uniforms.u_flickerIntensity, getGlobalVal('Opacity', 'flickerIntensity')); this.gl.uniform1f(this.uniforms.u_flickerFade, getGlobalVal('Opacity', 'flickerFade')); this.gl.uniform1f(this.uniforms.u_seepAmount, getGlobalVal('Seep', 'seepAmount')); this.gl.uniform1f(this.uniforms.u_seepIntensity, getGlobalVal('Seep', 'seepIntensity')); this.gl.uniform1i(this.uniforms.u_useBackground, useBg); this.gl.uniform1f(this.uniforms.u_maskFeather, maskFeather); this.gl.uniform1i(this.uniforms.u_tex, 0); this.gl.uniform1i(this.uniforms.u_feedbackTex, 1); this.gl.uniform1i(this.uniforms.u_maskTex, 2); this.gl.uniform1i(this.uniforms.u_backgroundTex, 3); this.gl.activeTexture(this.gl.TEXTURE1); this.gl.bindTexture(this.gl.TEXTURE_2D, this.textures.feedbackA); this.gl.uniform1i(this.uniforms.u_isFeedbackPass, 1); this.gl.bindFramebuffer(this.gl.FRAMEBUFFER, this.framebuffers.feedback); this.gl.framebufferTexture2D(this.gl.FRAMEBUFFER, this.gl.COLOR_ATTACHMENT0, this.gl.TEXTURE_2D, this.textures.feedbackB, 0); this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4); this.gl.uniform1i(this.uniforms.u_isFeedbackPass, 0); this.gl.bindFramebuffer(this.gl.FRAMEBUFFER, null); this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4); [this.textures.feedbackA, this.textures.feedbackB] = [this.textures.feedbackB, this.textures.feedbackA]; }
    };
    const BodySegmenter = { /* ... Full, unchanged BodySegmenter object ... */
      segmenter: null, lastResult: null, isReady: false, isBusy: false, lastUpdateTime: 0, minInterval: 60,
      async init() { if (this.isReady) return true; try { this.segmenter = new window.SelfieSegmentation({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}` }); this.segmenter.setOptions({ modelSelection: 1 }); this.segmenter.onResults(res => { this.lastResult = res.segmentationMask; this.isBusy = false; }); await this.segmenter.initialize(); this.isReady = true; return true; } catch (err) { console.error("Selfie Segmentation initialization failed:", err); return false; } },
      update(video) { const now = performance.now(); if (this.isReady && !this.isBusy && (now - this.lastUpdateTime) > this.minInterval) { this.isBusy = true; this.lastUpdateTime = now; this.segmenter.send({ image: video }); } }
    };

    const App = {
      stream: null, rafId: null,
      setStatus(text, isError = false) {
        channel.postMessage({ type: 'statusUpdate', payload: { text, isError } });
      },
      async start() {
        if (!navigator.mediaDevices?.getUserMedia) return this.setStatus('getUserMedia not supported.', true);
        try {
          this.setStatus('Requesting camera...');
          this.stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user', width: 1280, height: 720 }, audio: false });
          DOM.video.srcObject = this.stream;
          await new Promise(resolve => { DOM.video.onloadedmetadata = resolve; });
          await DOM.video.play();
          this.setStatus('Initializing GL...');
          const uniformKeys = [ 'u_resolution', 'u_time', 'u_isFeedbackPass', 'u_tex', 'u_feedbackTex', 'u_maskTex', 'u_backgroundTex', 'u_useBackground', 'u_maskFeather', 'u_overallOpacity', 'u_flickerPerSecond', 'u_flickerDuration', 'u_flickerIntensity', 'u_flickerFade', 'u_seepAmount', 'u_seepIntensity', 'u_feedbackAmount', 'u_feedbackZoom', 'u_glitchIntensity', 'u_glitchBlockSize', 'u_rgbShift', 'u_noiseAmount', 'u_noiseSpeed', 'u_vignette', 'u_globalSmearIntensity', 'u_globalSmearAngle', 'u_spotSmearIntensity', 'u_spotSmearDensity', 'u_spotSmearSize' ];
          Renderer.init(DOM.glcanvas, vertSrc, fragSrc, uniformKeys);
          Renderer.fit(DOM.video);
          this.setStatus('Initializing Body Segmentation...');
          if (!(await BodySegmenter.init())) return this.setStatus('Segmentation Failed', true);
          this.setStatus('Running');
          if (this.rafId) cancelAnimationFrame(this.rafId);
          this.loop();
        } catch (err) { this.setStatus(`Error: ${err.message}`, true); }
      },
      stop() {
        if (this.rafId) cancelAnimationFrame(this.rafId);
        this.rafId = null;
        if (this.stream) this.stream.getTracks().forEach(t => t.stop());
        this.stream = null;
        this.setStatus('Terminated');
      },
      loop(time) {
        this.rafId = requestAnimationFrame(t => this.loop(t));
        const video = DOM.video;
        if (!video.videoWidth || !Renderer.gl) return;
        Renderer.fit(video);
        BodySegmenter.update(video);
        Renderer.drawMask(video, BodySegmenter.lastResult);
        
        const animate = currentState.checkboxes ? currentState.checkboxes.animateChk : true;
        const t = animate ? time / 1000 : 0;
        
        const backgroundEl = !DOM.backgroundImage.classList.contains('hidden') ? DOM.backgroundImage : DOM.backgroundMedia;
        Renderer.render({
          video: video, t: t, state: currentState,
          backgroundMedia: backgroundEl,
          useBg: currentState.checkboxes ? currentState.checkboxes.useBgChk : false,
          maskFeather: currentState.misc ? parseFloat(currentState.misc.maskFeather) : 0.15
        });

        const statusText = BodySegmenter.lastResult ? `BODY DETECTED [${Renderer.gl.canvas.width}x${Renderer.gl.canvas.height}]` : 'NO SIGNAL...';
        this.setStatus(statusText);
      },
      handleCommand(command) {
        if (command === 'start') this.start();
        else if (command === 'stop') this.stop();
      },
      handleStateUpdate(newState) {
          currentState = newState;
          // Handle immediate state changes that aren't in the render loop
          if (currentState.checkboxes) {
            DOM.glcanvas.style.transform = currentState.checkboxes.mirrorChk ? 'scaleX(-1)' : 'none';
          }
      },
       handleBackgroundUpdate(bg) {
          const url = URL.createObjectURL(bg.file);
          if (bg.file.type.startsWith('image/')) {
              DOM.backgroundImage.src = url;
              DOM.backgroundImage.classList.remove('hidden');
              DOM.backgroundMedia.classList.add('hidden');
              DOM.backgroundMedia.pause();
              DOM.backgroundMedia.src = '';
          } else if (bg.file.type.startsWith('video/')) {
              DOM.backgroundMedia.src = url;
              DOM.backgroundMedia.play();
              DOM.backgroundMedia.classList.remove('hidden');
              DOM.backgroundImage.classList.add('hidden');
              DOM.backgroundImage.src = '';
          }
      }
    };

    channel.onmessage = (event) => {
      const { type, payload } = event.data;
      if (type === 'command') App.handleCommand(payload);
      if (type === 'stateUpdate') App.handleStateUpdate(payload);
      if (type === 'backgroundUpdate') App.handleBackgroundUpdate(payload);
    };

    App.setStatus('IDLE');
    
  })();
  </script>
</body>
</html>
